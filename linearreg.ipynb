{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     111.5\n",
      "1      98.0\n",
      "2     125.5\n",
      "3      39.0\n",
      "4      58.0\n",
      "5      21.0\n",
      "6      96.0\n",
      "7      50.0\n",
      "8      91.0\n",
      "9      28.0\n",
      "10    142.0\n",
      "11     80.0\n",
      "12     58.0\n",
      "13     -7.0\n",
      "14    125.0\n",
      "15     63.0\n",
      "16     56.0\n",
      "17     44.0\n",
      "18     15.0\n",
      "19    125.0\n",
      "20     88.0\n",
      "21      7.0\n",
      "22    102.0\n",
      "23     11.0\n",
      "24     71.0\n",
      "25     55.0\n",
      "26      0.0\n",
      "27     84.0\n",
      "28    109.0\n",
      "29    136.0\n",
      "30    102.0\n",
      "31     42.0\n",
      "32     44.0\n",
      "33    128.0\n",
      "34     99.0\n",
      "35     99.0\n",
      "36    114.0\n",
      "37    101.0\n",
      "38     10.0\n",
      "39     65.0\n",
      "40     32.0\n",
      "41     69.0\n",
      "42     14.0\n",
      "43     85.0\n",
      "44     43.0\n",
      "45     32.0\n",
      "46     62.0\n",
      "47    100.0\n",
      "48     97.0\n",
      "49     83.0\n",
      "50     84.0\n",
      "51     75.0\n",
      "52     44.0\n",
      "Name: score, dtype: float64\n",
      "Weights: [ 1.01036427e-04  2.04877093e-05 -7.23505911e-04  9.99366766e-01\n",
      "  2.00323733e+00 -1.00312695e+00 -3.05246164e-02 -3.75379064e-02]\n",
      "Intercept: 0.05424217847681234\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Replace these variables with your PostgreSQL connection details\n",
    "db_host = \"localhost\"\n",
    "db_port = 5432\n",
    "db_name = \"postgres\"\n",
    "db_user = \"postgres\"\n",
    "db_password = \"postgres\"\n",
    "\n",
    "# Create an SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Query data from the database using SQLAlchemy engine\n",
    "query = \"SELECT * FROM merchant_logs\"\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "\n",
    "# Extract features (independent variables) and target variable\n",
    "X_train =df[['transaction_amount', 'refund_amount', 'pa_customer', 'ntb_approved',\n",
    "          'vas_service_count', 'ntb_reject', 'dpd_count', 'npa_count']]\n",
    "y_train = df['score']\n",
    "\n",
    "print(y_train)\n",
    "\n",
    "# Create and train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print the learned weights and intercept\n",
    "weights = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "print(f\"Weights: {weights}\")\n",
    "print(f\"Intercept: {intercept}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df[['transaction_amount', 'refund_amount', 'pa_customer', 'ntb_approved',\n",
    "             'vas_service_count', 'ntb_reject', 'dpd_count', 'npa_count']]\n",
    "predicted_scores = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.10680668e+02,  9.85278818e+01,  1.25773267e+02,  3.91761926e+01,\n",
       "        5.81592311e+01,  2.08794472e+01,  9.58683457e+01,  5.03916448e+01,\n",
       "        9.12647417e+01,  2.78944257e+01,  1.42206515e+02,  7.98612444e+01,\n",
       "        5.79116655e+01, -6.83625722e+00,  1.24840146e+02,  6.30076615e+01,\n",
       "        5.63468792e+01,  4.36989847e+01,  1.45479863e+01,  1.25014202e+02,\n",
       "        8.73123505e+01,  6.98449870e+00,  1.01669612e+02,  1.13411683e+01,\n",
       "        7.15448899e+01,  5.44926502e+01, -1.15467397e-01,  8.41656058e+01,\n",
       "        1.08456415e+02,  1.36523800e+02,  1.02109426e+02,  4.17456332e+01,\n",
       "        4.43664647e+01,  1.27658643e+02,  9.92011886e+01,  9.85701445e+01,\n",
       "        1.14385514e+02,  1.00806841e+02,  9.79261067e+00,  6.53127547e+01,\n",
       "        3.26677943e+01,  6.92184880e+01,  1.41410680e+01,  8.52135919e+01,\n",
       "        4.30272660e+01,  3.16202995e+01,  6.19188639e+01,  9.98804730e+01,\n",
       "        9.69649035e+01,  8.25768664e+01,  8.48396553e+01,  7.47003756e+01,\n",
       "        4.36907381e+01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_scores'] = predicted_scores\n",
    "df.to_sql('merchant_logs', engine, index=False, if_exists='replace')\n",
    "\n",
    "# Commit changes\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "storing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_regression_model.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model, 'linear_regression_model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained model from the file\n",
    "model = joblib.load('linear_regression_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_production is your new dataset in production\n",
    "predicted_scores_production = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.10680668e+02  9.85278818e+01  1.25773267e+02  3.91761926e+01\n",
      "  5.81592311e+01  2.08794472e+01  9.58683457e+01  5.03916448e+01\n",
      "  9.12647417e+01  2.78944257e+01  1.42206515e+02  7.98612444e+01\n",
      "  5.79116655e+01 -6.83625722e+00  1.24840146e+02  6.30076615e+01\n",
      "  5.63468792e+01  4.36989847e+01  1.45479863e+01  1.25014202e+02\n",
      "  8.73123505e+01  6.98449870e+00  1.01669612e+02  1.13411683e+01\n",
      "  7.15448899e+01  5.44926502e+01 -1.15467397e-01  8.41656058e+01\n",
      "  1.08456415e+02  1.36523800e+02  1.02109426e+02  4.17456332e+01\n",
      "  4.43664647e+01  1.27658643e+02  9.92011886e+01  9.85701445e+01\n",
      "  1.14385514e+02  1.00806841e+02  9.79261067e+00  6.53127547e+01\n",
      "  3.26677943e+01  6.92184880e+01  1.41410680e+01  8.52135919e+01\n",
      "  4.30272660e+01  3.16202995e+01  6.19188639e+01  9.98804730e+01\n",
      "  9.69649035e+01  8.25768664e+01  8.48396553e+01  7.47003756e+01\n",
      "  4.36907381e+01]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incremental training of the model based on feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update existing model with new data incrementally\n",
    "existing_model = joblib.load('linear_regression_model.joblib')\n",
    "\n",
    "for new_data_batch in new_data_batches:\n",
    "    X_train = df[['transaction_amount', 'refund_amount', 'pa_customer', 'ntb_approved',\n",
    "             'vas_service_count', 'ntb_reject', 'dpd_count', 'npa_count']]\n",
    "    y_train = df['score']\n",
    "    existing_model.partial_fit(X_train, y_train)\n",
    "\n",
    "#saving the model\n",
    "joblib.dump(existing_model, 'updated_linear_reg_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
